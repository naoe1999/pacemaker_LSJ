{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIA Pacemaker - Python 과정\n",
    "\n",
    "# Python 실습예제 #4\n",
    "\n",
    "기초부터 문제까지 차근차근 Build-up\n",
    "\n",
    "- requests\n",
    "- beautifulsoup\n",
    "- selenium\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연습 1 - requests (html 문서 가져오기)\n",
    "\n",
    "사용 방법  \n",
    "\n",
    "1. requests 패키지 import\n",
    "2. 가져올 url을 문자열로 입력하기\n",
    "3. requests의 get 함수를 이용해 url로부터 html이 담긴 자료 받아오기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/brix/opt/anaconda3/envs/basic/lib/python3.8/site-packages (2.27.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/brix/opt/anaconda3/envs/basic/lib/python3.8/site-packages (4.10.0)\n",
      "Requirement already satisfied: selenium in /Users/brix/opt/anaconda3/envs/basic/lib/python3.8/site-packages (4.1.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/brix/opt/anaconda3/envs/basic/lib/python3.8/site-packages (from requests) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/brix/opt/anaconda3/envs/basic/lib/python3.8/site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/brix/opt/anaconda3/envs/basic/lib/python3.8/site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/brix/opt/anaconda3/envs/basic/lib/python3.8/site-packages (from requests) (1.26.8)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/brix/opt/anaconda3/envs/basic/lib/python3.8/site-packages (from beautifulsoup4) (2.3.1)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Users/brix/opt/anaconda3/envs/basic/lib/python3.8/site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: trio~=0.17 in /Users/brix/opt/anaconda3/envs/basic/lib/python3.8/site-packages (from selenium) (0.19.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/brix/opt/anaconda3/envs/basic/lib/python3.8/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: sniffio in /Users/brix/opt/anaconda3/envs/basic/lib/python3.8/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: outcome in /Users/brix/opt/anaconda3/envs/basic/lib/python3.8/site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in /Users/brix/opt/anaconda3/envs/basic/lib/python3.8/site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Users/brix/opt/anaconda3/envs/basic/lib/python3.8/site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/brix/opt/anaconda3/envs/basic/lib/python3.8/site-packages (from trio-websocket~=0.9->selenium) (1.0.0)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in /Users/brix/opt/anaconda3/envs/basic/lib/python3.8/site-packages (from urllib3<1.27,>=1.21.1->requests) (22.0.0)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in /Users/brix/opt/anaconda3/envs/basic/lib/python3.8/site-packages (from urllib3<1.27,>=1.21.1->requests) (36.0.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/brix/opt/anaconda3/envs/basic/lib/python3.8/site-packages (from cryptography>=1.3.4->urllib3<1.27,>=1.21.1->requests) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /Users/brix/opt/anaconda3/envs/basic/lib/python3.8/site-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3<1.27,>=1.21.1->requests) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/brix/opt/anaconda3/envs/basic/lib/python3.8/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# 필요한 패키지들을 설치합니다. 최초 1회만 실행하면 됩니다.\n",
    "\n",
    "%pip install requests beautifulsoup4 selenium\n",
    "\n",
    "# 설치가 끝나면 kernel을 \"Restart\" 합니다.\n",
    "\n",
    "# 크롬드라이버는 https://wikidocs.net/137919 를 참조하여 설치합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!doctype html> <html lang=\"ko\"> <head> <meta charset=\"utf-8\"> <meta name=\"referrer\" content=\"always\">  <meta name=\"format-detection\" content=\"telephone=no,address=no,email=no\"> <meta name=\"viewport\" content=\"width=device-width,initial-scale=1.0,maximum-scale=2.0\"> <meta property=\"og:title\" content=\"금메달 : 네이버 뉴스검색\"/> <meta property=\"og:image\" content=\"https://ssl.pstatic.net/sstatic/search/common/og_v3.png\"> <meta property=\"og:description\" content=\"'금메달'의 네이버 뉴스검색 결과입니다.\"> <meta name=\"description\" lang=\"ko\" content=\"'금메달'의 네이버 뉴스검색 결과입니다.\"> <title>금메달 : 네이버 뉴스검색</title> <link rel=\"shortcut icon\" href=\"https://ssl.pstatic.net/sstatic/search/favicon/favicon_191118_pc.ico\">  <link rel=\"search\" type=\"application/opensearchdescription+xml\" href=\"https://ssl.pstatic.net/sstatic/search/opensearch-description.https.xml\" title=\"Naver\" /><link rel=\"stylesheet\" type=\"text/css\" href=\"https://ssl.pstatic.net/sstatic/search/pc/css/search1_220210.css\"> <link rel=\"stylesheet\" type=\"text/css\" href=\"htt\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "import requests\n",
    "\n",
    "\n",
    "#2\n",
    "url = 'https://search.naver.com/search.naver?where=news&sm=tab_jum&query=금메달'\n",
    "\n",
    "\n",
    "#3\n",
    "response = requests.get(url)\n",
    "\n",
    "html_text = response.text\n",
    "\n",
    "\n",
    "# 일부분을 출력해보자\n",
    "print(html_text[:1000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연습 2 - beautifulsoup (긴 html 문서에서 원하는 것을 가져온다.)\n",
    "\n",
    "사용방법\n",
    "1. beautifulsoup 패키지 import\n",
    "2. html을 정리된 형태로 변환시키기 (beautifulsoup 객체)\n",
    "3. select_one 함수 사용해서 뉴스 제목 가져오기\n",
    "\n",
    "\n",
    "- 먼저 ctrl+Shift+c 혹은 F12를 눌러 개발자 도구를 실행합니다. \n",
    "- 그 후, 원하는 정보가 담긴 부분에 커서를 올리면 해당 class의 이름을 볼 수 있습니다. ex) a.news_tit 등등..\n",
    "\n",
    "\n",
    "<img src='exercise04_image01.png' width=\"800px\" height=\"450px\"></img>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "올림픽 금메달 따면 8억8000만원 '최대 포상금' 준다는 이 나라, 어디길래\n",
      "http://news.mk.co.kr/newsRead.php?no=143136&year=2022\n"
     ]
    }
   ],
   "source": [
    "#1 \n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "\n",
    "#2\n",
    "soup = bs(html_text, 'html.parser')\n",
    "\n",
    "\n",
    "#3\n",
    "a_tag = soup.select_one('a.news_tit')\n",
    "title = a_tag.get_text()\n",
    "href = a_tag.attrs['href']\n",
    "\n",
    "# 위에서 'news_tit' 클래스를 가진 <a ...> 태그 중 하나를 가져왔다.\n",
    "# 텍스트와 링크를 출력해보자\n",
    "print(title)\n",
    "print(href)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 문제 1\n",
    "#### 기사 제목 웹스크래핑하기 \n",
    "\n",
    "1. '쇼트트랙'을 검색한 네이버 뉴스 페이지를 가져오고 (html) \n",
    "2. 이 페이지에 있는 뉴스 제목과 링크 주소를 전부 출력하세요.\n",
    "\n",
    "정보: \n",
    "1. 네이버 뉴스 검색 페이지 주소: https://search.naver.com/search.naver?where=news&sm=tab_jum&query=원하는검색어\n",
    "2. 뉴스 링크에 해당하는 태그.클래스:  a.news_tit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[베이징올림픽]16일 쇼트트랙 여자 1500m 열려...마지막 '금' 사냥 링크: http://www.fnnews.com/news/202202151533007608\n",
      "한국 대표팀이 반칙왕?…황당한 中 쇼트트랙 영화 링크: http://news.mk.co.kr/newsRead.php?no=143442&year=2022\n",
      "[올림픽] 훈련하는 쇼트트랙 대표팀 링크: http://yna.kr/PYH20220215141200013?did=1196m\n",
      "[인터뷰]쇼트트랙 최민정 \"내일이면 4년 준비도 끝…후회없이!\" 링크: http://www.newsis.com/view/?id=NISX20220215_0001759903&cID=10511&pID=10500\n",
      "[올림픽] 쇼트트랙 최민정, 여자 1500ｍ 준준결승서 中 장위팅과 대결 링크: https://www.news1.kr/articles/?4585718\n",
      "[올림픽] 쇼트트랙 최민정, 여자 1,500ｍ 준준결승서 스휠팅 피했다 링크: http://yna.kr/AKR20220215110800007?did=1195m\n",
      "韓쇼트트랙 남매 '마지막 골든데이' 링크: https://www.hankyung.com/sports/article/202202154840i\n",
      "[올림픽] 김아랑의 부정 출발, 실수 아닌 작전…한국 쇼트트랙의 수싸움 링크: http://yna.kr/AKR20220215124400007?did=1195m\n",
      "[올림픽] 쇼트트랙 박장혁, 다친 손으로 계주 출전 \"손 걸고 타겠다\" 링크: http://yna.kr/AKR20220214158800007?did=1195m\n",
      "[올림픽] 한국 쇼트트랙, 16일 여자 1,500ｍ·남자 계주서 '마지막 질주' 링크: http://yna.kr/AKR20220215001600007?did=1195m\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "\n",
    "\n",
    "url = 'https://search.naver.com/search.naver?where=news&sm=tab_jum&query=쇼트트랙'\n",
    "\n",
    "\n",
    "response = requests.get(url)\n",
    "html_text = response.text\n",
    "\n",
    "soup = bs(html_text, 'html.parser')\n",
    "\n",
    "a_tags = soup.select('a.news_tit')\n",
    "\n",
    "for a in a_tags:\n",
    "    href = a.attrs['href']\n",
    "    title = a.get_text()\n",
    "    print(title, '링크:', href)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 2\n",
    "#### 원하는 지역의 기온 가져오기\n",
    "\n",
    "1. input을 통해 지역을 입력받고,\n",
    "2. 해당 지역의 기온 정보 출력하기\n",
    "\n",
    "정보:\n",
    "1. 특정지역의 네이버 날씨 검색 주소: https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=1&ie=utf8&query=OO날씨 \n",
    "2. 기온이 들어있는 태그.클래스:  크롬 개발자 모드를 사용하여 직접 알아내 보세요.  힌트: div 태크 중 특정 클래스 (div.class명)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "서울 기온:  현재 온도-7° \n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "\n",
    "\n",
    "location = input('지역을 입력하세요: ')\n",
    "url = f'https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=1&ie=utf8&query={location}날씨'\n",
    "\n",
    "\n",
    "response = requests.get(url)\n",
    "html_text = response.text\n",
    "\n",
    "\n",
    "soup = bs(html_text, 'html.parser')\n",
    "\n",
    "temperature = soup.select_one('div.temperature_text').get_text()\n",
    "\n",
    "print(location, '기온:', temperature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 연습 3 - selenium으로 화면 조작하기\n",
    "1. selenium 패키지 import\n",
    "2. time 모듈 import\n",
    "3. 크롬 드라이버 실행\n",
    "4. 크롬 드라이버로 url 실행\n",
    "5. 검색과 클릭 조작하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "\n",
    "#2\n",
    "import time\n",
    "\n",
    "\n",
    "#3\n",
    "s = Service('/Users/brix/.chromedriver')\n",
    "driver = webdriver.Chrome(service=s)\n",
    "# 크롬드라이버 사용법 사이트 ( https://jaehyongschool.tistory.com/16 )\n",
    "\n",
    "\n",
    "#4 \n",
    "driver.get('https://www.naver.com/')\n",
    "time.sleep(2)   # 2초간 대기\n",
    "\n",
    "\n",
    "#5\n",
    "# 검색어 창을 찾아 search_box 변수에 저장 - css_selector 이용\n",
    "search_box = driver.find_element(By.CSS_SELECTOR, 'input#query.input_text')\n",
    "\n",
    "# 검색어 창에 텍스트 입력 (키보드 입력)\n",
    "search_box.send_keys('대한민국 금메달')\n",
    "search_box.send_keys(Keys.RETURN)\n",
    "time.sleep(2)   # 2초간 대기\n",
    " \n",
    "# 뉴스 탭 찾아서 클릭하기 - css_selector 이용\n",
    "driver.find_element(By.CSS_SELECTOR, '#lnb > div.lnb_group > div > ul > li:nth-child(8) > a').click()\n",
    "time.sleep(2)   # 2초간 대기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 3\n",
    "#### 구글에서 \"코스피 지수\" 검색하여 가져오기\n",
    "\n",
    "1. selenium을 통해 구글 검색으로 이동\n",
    "2. 검색어 창을 찾아서 \"코스피 지수\" 검색\n",
    "3. 코스피 지수 값을 얻어와서 출력\n",
    "\n",
    "힌트: \n",
    "- 구글 검색창 찾기:  driver.find_element(By.NAME, 'q')\n",
    "- 검색 결과 element:  driver.find_element(By.XPATH, '크롬 개발자 모드를 통해 알아내보자')\n",
    "- element에서 텍스트 가져오기:  element.get_attribute(\"innerHTML\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,676.54\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "\n",
    "s = Service('/Users/brix/.chromedriver')\n",
    "driver = webdriver.Chrome(service=s)\n",
    "\n",
    "\n",
    "# 구글로 이동\n",
    "driver.get('https://www.google.com/')\n",
    "time.sleep(2)   # 2초간 대기\n",
    "\n",
    "\n",
    "# 검색창\n",
    "search_box = driver.find_element(By.NAME, 'q')\n",
    "\n",
    "\n",
    "# 검색어 창에 텍스트 입력 (키보드 입력)\n",
    "search_box.send_keys('코스피 지수')\n",
    "search_box.send_keys(Keys.RETURN)\n",
    "time.sleep(2)   # 2초간 대기\n",
    "\n",
    "\n",
    "# 원하는 내용 가져오기 - css_selector 이용\n",
    "element = driver.find_element(By.XPATH, '//*[@id=\"knowledge-finance-wholepage__entity-summary\"]/div/g-card-section/div/g-card-section/div[2]/div[1]/span[1]/span/span')\n",
    "print(element.get_attribute(\"innerHTML\"))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
